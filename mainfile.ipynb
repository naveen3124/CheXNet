{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "l = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.10.0', False, False, '')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from urllib import request\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "tf.__version__, tf.test.is_gpu_available(), tf.test.is_built_with_cuda(), tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Path     Sex  Age  \\\n",
      "0  CheXpert-v1.0-small/train/patient00001/study1/...  Female   68   \n",
      "1  CheXpert-v1.0-small/train/patient00002/study2/...  Female   87   \n",
      "2  CheXpert-v1.0-small/train/patient00002/study1/...  Female   83   \n",
      "3  CheXpert-v1.0-small/train/patient00002/study1/...  Female   83   \n",
      "4  CheXpert-v1.0-small/train/patient00003/study1/...    Male   41   \n",
      "\n",
      "  Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
      "0         Frontal    AP         1.0                         NaN           NaN   \n",
      "1         Frontal    AP         NaN                         NaN          -1.0   \n",
      "2         Frontal    AP         NaN                         NaN           NaN   \n",
      "3         Lateral   NaN         NaN                         NaN           NaN   \n",
      "4         Frontal    AP         NaN                         NaN           NaN   \n",
      "\n",
      "   Lung Opacity  Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
      "0           NaN          NaN    NaN            NaN        NaN          NaN   \n",
      "1           1.0          NaN   -1.0           -1.0        NaN         -1.0   \n",
      "2           1.0          NaN    NaN           -1.0        NaN          NaN   \n",
      "3           1.0          NaN    NaN           -1.0        NaN          NaN   \n",
      "4           NaN          NaN    1.0            NaN        NaN          NaN   \n",
      "\n",
      "   Pneumothorax  Pleural Effusion  Pleural Other  Fracture  Support Devices  \n",
      "0           0.0               NaN            NaN       NaN              1.0  \n",
      "1           NaN              -1.0            NaN       1.0              NaN  \n",
      "2           NaN               NaN            NaN       1.0              NaN  \n",
      "3           NaN               NaN            NaN       1.0              NaN  \n",
      "4           0.0               NaN            NaN       NaN              NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Dataset = \"CheXpert-v1.0-small\"\n",
    "data = pd.read_csv(os.path.join(Dataset,\"train.csv\"))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _img_string_to_tensor(image_string, image_size=(299, 299)):\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    # Convert from full range of uint8 to range [0,1] of float32.\n",
    "    image_decoded_as_float = tf.image.convert_image_dtype(image_decoded, dtype=tf.float32)\n",
    "    # Resize to expected\n",
    "    image_resized = tf.image.resize_images(image_decoded_as_float, size=image_size)\n",
    "    \n",
    "    return image_resized\n",
    "\n",
    "def make_dataset(file_pattern, image_size=(299, 299), shuffle=False, batch_size=64, num_epochs=None, buffer_size=4096):\n",
    "    \n",
    "    def _path_to_img(path):\n",
    "        # Get the parent folder of this file to get it's class name\n",
    "        label = tf.string_split([path], delimiter='/').values[-2]\n",
    "        \n",
    "        \n",
    "\n",
    "        # Read in the image from disk\n",
    "        image_string = tf.read_file(path)\n",
    "        image_resized = _img_string_to_tensor(image_string, image_size)\n",
    "        \n",
    "        return { 'image': image_resized }, label\n",
    "    \n",
    "    dataset = tf.data.Dataset.list_files(file_pattern)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size, num_epochs))\n",
    "    else:\n",
    "        dataset = dataset.repeat(num_epochs)\n",
    "\n",
    "    dataset = dataset.map(_path_to_img, num_parallel_calls=os.cpu_count())\n",
    "    dataset = dataset.batch(batch_size).prefetch(buffer_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_dataset(\"CheXpert-v1.0-small\\\\train\\**\\*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    is_training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    module_training = is_training and params.get('train_module', False)\n",
    "\n",
    "    module = hub.Module(params['module_spec'], trainable=module_training, name=params['module_name'])\n",
    "    bottleneck_tensor = module(features['image'])\n",
    "\n",
    "    NUM_CLASSES = len(params['label_vocab'])\n",
    "    logit_units = 1 if NUM_CLASSES == 2 else NUM_CLASSES\n",
    "    logits = l.Dense(logit_units)(bottleneck_tensor)\n",
    "\n",
    "    if NUM_CLASSES == 2:\n",
    "        head = tf.contrib.estimator.binary_classification_head(label_vocabulary=params['label_vocab'])\n",
    "    else:\n",
    "        head = tf.contrib.estimator.multi_class_head(n_classes=NUM_CLASSES, label_vocabulary=params['label_vocab'])\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])\n",
    "    return head.create_estimator_spec(\n",
    "        features, mode, logits, labels, optimizer=optimizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_directory, data_directory):\n",
    "\n",
    "    params = {\n",
    "        'module_spec': 'https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/1',\n",
    "        'module_name': 'resnet_v2_50',\n",
    "        'learning_rate': 1e-3,\n",
    "        'train_module': False,  # Whether we want to finetune the module\n",
    "        'label_vocab': os.listdir(os.path.join(Dataset, 'valid'))\n",
    "    }\n",
    "\n",
    "    run_config = tf.estimator.RunConfig()\n",
    "\n",
    "    classifier = tf.estimator.Estimator(\n",
    "        model_fn=model_fn,\n",
    "        model_dir=model_directory,\n",
    "        config=run_config,\n",
    "        params=params\n",
    "    )\n",
    "\n",
    "    input_img_size = hub.get_expected_image_size(hub.Module(params['module_spec']))\n",
    "    \n",
    "    train_files = os.path.join(data_directory, 'train', '**\\*.jpg')\n",
    "    print(train_files)\n",
    "    train_input_fn = lambda: make_dataset(train_files, image_size=input_img_size, batch_size=8, shuffle=True)\n",
    "    train_spec = tf.estimator.TrainSpec(train_input_fn, max_steps=20)\n",
    "\n",
    "    eval_files = os.path.join(data_directory, 'valid', '**\\*.jpg')\n",
    "    eval_input_fn = lambda: make_dataset(eval_files, image_size=input_img_size, batch_size=1)\n",
    "    eval_spec = tf.estimator.EvalSpec(eval_input_fn)\n",
    "\n",
    "    tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'chexpert_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000009191329A90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "CheXpert-v1.0-small\\train\\**\\*.jpg\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    }
   ],
   "source": [
    "model_directory = \"chexpert_model\"\n",
    "Dataset = \"CheXpert-v1.0-small\"\n",
    "train(model_directory,Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
